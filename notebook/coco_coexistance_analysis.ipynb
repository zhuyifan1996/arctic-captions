{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "COCO_PATH = '../../data/coco/'\n",
    "COCO_ANNO_PATH = COCO_PATH + 'annotations/'\n",
    "\n",
    "# load the data from captions\n",
    "import json\n",
    "from six.moves import cPickle as pkl\n",
    "\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "\n",
    "CWD = os.getcwd()\n",
    "COCO_TEXT_PATH = CWD+'/../../coco-text/'\n",
    "sys.path.insert(0, COCO_TEXT_PATH)\n",
    "import coco_text as ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Frequency Analysis\n",
    "\"\"\"\n",
    "with open(COCO_ANNO_PATH + 'captions_train2014.json') as f:\n",
    "    coco_captions = json.load(f)\n",
    "    \n",
    "    # build the reverse dictionary, from img_id to captions, img_infos, and annotations\n",
    "    img_captions = {}\n",
    "    for img_info in coco_captions['images']:\n",
    "        mid = str(img_info['id'])\n",
    "        if not mid in img_captions:\n",
    "            img_captions[mid] = {}\n",
    "        img_captions[mid]['image'] = img_info\n",
    "        \n",
    "    for cap_info in coco_captions['annotations']:\n",
    "        mid = str(cap_info['image_id'])\n",
    "        if not 'annotation' in img_captions[mid]:\n",
    "            img_captions[mid]['annotation'] = []\n",
    "            img_captions[mid]['captions'] = ''\n",
    "        img_captions[mid]['annotation'].append(cap_info)\n",
    "        img_captions[mid]['captions'] += str(cap_info['caption']) + ' '\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "0:00:03.017248\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Import Coco Text\n",
    "\"\"\"\n",
    "ct = ct.COCO_Text(COCO_PATH + 'COCO_Text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'captions': 'A suitcase that is next to a bag. A piece of luggage covered in luggage tags The luggage contains tags from several different locations. A piece of luggage that has paper tags on it. A suitcase is waiting to be claimed in an airport. ', 'image': {u'license': 3, u'file_name': u'COCO_train2014_000000294914.jpg', u'coco_url': u'http://mscoco.org/images/294914', u'height': 425, u'width': 640, u'date_captured': u'2013-11-18 11:18:21', u'flickr_url': u'http://farm4.staticflickr.com/3032/2538554933_c1bef44aab_z.jpg', u'id': 294914}, 'annotation': [{u'image_id': 294914, u'id': 749830, u'caption': u'A suitcase that is next to a bag.'}, {u'image_id': 294914, u'id': 752091, u'caption': u'A piece of luggage covered in luggage tags'}, {u'image_id': 294914, u'id': 754334, u'caption': u'The luggage contains tags from several different locations.'}, {u'image_id': 294914, u'id': 754460, u'caption': u'A piece of luggage that has paper tags on it.'}, {u'image_id': 294914, u'id': 755048, u'caption': u'A suitcase is waiting to be claimed in an airport.'}], 'texts': [{u'language': u'english', u'area': 540.1768517646655, u'class': u'machine printed', u'utf8_string': u'404', u'image_id': 294914, u'bbox': [304.53064067769816, 263.1979695431472, 17.268128161888683, 31.281725888324896], u'legibility': u'legible', u'id': 1057395}, {u'language': u'english', u'area': 377.1924568356719, u'id': 1057396, u'image_id': 294914, u'bbox': [273.23215838427484, 153.17258883248735, 12.951096121416548, 29.124365482233472], u'legibility': u'illegible', u'class': u'machine printed'}, {u'language': u'english', u'area': 356.3642461848053, u'class': u'machine printed', u'utf8_string': u'NR', u'image_id': 294914, u'bbox': [342.5074517548974, 315.4072997275363, 29.85074626865668, 11.938202247190993], u'legibility': u'legible', u'id': 1186970}, {u'language': u'not english', u'area': 222.37128961931853, u'id': 1186971, u'image_id': 294914, u'bbox': [393.85073533698693, 255.71628849158128, 7.164179104477597, 31.03932584269661], u'legibility': u'legible', u'class': u'machine printed'}, {u'language': u'not english', u'area': 518.8663424450775, u'id': 1186972, u'image_id': 294914, u'bbox': [266.0895413071362, 150.66010871630033, 15.522388059701484, 33.42696629213482], u'legibility': u'legible', u'class': u'machine printed'}]}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"extract coco-text annotations and pack into img-captions\"\"\"\n",
    "# print ct.getImgIds(imgIds=ct.train, catIds=[('legibility','legible')])\n",
    "# print ct.getAnnIds(imgIds=[294914])\n",
    "# print img_captions[\"294914\"]\n",
    "for imgId in img_captions.keys():\n",
    "    annIds = ct.getAnnIds(imgIds=[int(imgId)])\n",
    "    anns = ct.loadAnns(ids = annIds)\n",
    "    img_captions[imgId][\"texts\"] = anns\n",
    "\n",
    "print img_captions[\"294914\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "683\n"
     ]
    }
   ],
   "source": [
    "def filter_img_id(f):\n",
    "    \"\"\"Compute img-ids with a filter function f that takes in an annotation and returns a boolean.\"\"\"\n",
    "    output = []\n",
    "    for imgId in img_captions.keys():\n",
    "        tmp = filter(f, img_captions[imgId][\"texts\"])\n",
    "        if len(tmp)>0:\n",
    "            output.append(imgId)\n",
    "    return output\n",
    "\n",
    "def _is_large(ann, threshold = 0.1):\n",
    "    img_id = ann['image_id']\n",
    "    img_info = img_captions[str(img_id)]['image']\n",
    "    h,w = img_info['height'], img_info['width']\n",
    "    return ann['area']>=h*w*threshold\n",
    "\n",
    "results = [int(x) for x in filter_img_id(_is_large)]\n",
    "print len(results)\n",
    "\n",
    "with open('../../input/large_text_img_ids.pkl', 'w+') as f:\n",
    "    pkl.dump(results, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'GV'])\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def cal_coexist_rate(img_id, debug=False):\n",
    "    cap = img_captions[img_id]['captions'].upper()\n",
    "    if debug: \n",
    "        print 'Captions is :\\n%s\\n'%cap\n",
    "\n",
    "    cap_words = set(re.split('([,.])*\\s', cap))\n",
    "    if debug:\n",
    "        print '%s\\n'%cap_words\n",
    "\n",
    "    texts = ct.loadAnns(ct.getAnnIds(imgIds=int(img_id)))\n",
    "    text_words = set()\n",
    "    coexist_count = 0\n",
    "    for text in texts:\n",
    "        if not 'utf8_string' in text:\n",
    "            continue\n",
    "        words = text['utf8_string'].upper().split(' ')\n",
    "        for word in words:\n",
    "            if word in text_words:\n",
    "                continue\n",
    "            else:\n",
    "                text_words.add(word)\n",
    "\n",
    "            if word in cap_words:\n",
    "                if debug:\n",
    "                    print 'Word \"%s\" in caption.'%word\n",
    "                coexist_count = coexist_count + 1\n",
    "\n",
    "    print text_words\n",
    "    print coexist_count/float(len(set(text_words)))\n",
    "    return coexist_count/float(len(set(text_words))) \n",
    "\n",
    "# cal_coexist_rate('8006')\n",
    "cal_coexist_rate('296614')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating conditional coexistence rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"helper filtering functions\"\"\"\n",
    "def exclude_small_text(anns, img_id, threshold=0.1):\n",
    "    \"\"\"filter out the text annotations with a bounding box smaller than [threshold]*img_area\"\"\"\n",
    "    img_info = img_captions[img_id]['image']\n",
    "    h,w = img_info['height'], img_info['width']\n",
    "    return filter(lambda ann: ann['area']>=h*w*threshold, anns)\n",
    "\n",
    "def exclude_corner_text(anns, img_id, threshold=0.1):\n",
    "    \"\"\"filter out the text annotations on sides and corners\"\"\"\n",
    "    img_info = img_captions[img_id]['image']\n",
    "    h,w = img_info['height'], img_info['width']\n",
    "    def _judge(ann):\n",
    "        [x,y,bw,bh]=ann['bbox']\n",
    "        return  x>=threshold*w and \\\n",
    "                x+bw<=(1-threshold)*w and \\\n",
    "                y+bh<=(1-threshold)*h and \\\n",
    "                y>=threshold*h\n",
    "    return filter(_judge, anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"This function calculates coexistence rate in the following manner:\n",
    "For an image I, get a bag of words (no duplicate) S that appear in it, get the count\n",
    "of words k that appear in I's caption. \n",
    "Return k/|S|\"\"\"\n",
    "\n",
    "def calculate_population_coexist_stat(flags={}):\n",
    "    \"\"\"flag: \n",
    "    [] -- all captions\n",
    "    size: n -- excluding small bboxes with size less than n\n",
    "    corner: d -- excluding all texts entirely within d pixels to the sides\"\"\"\n",
    "    coexists = []\n",
    "\n",
    "    for img_id in img_captions.keys():\n",
    "        cap = img_captions[img_id]['captions'].upper()\n",
    "        cap_words = set(re.split('([,.])*\\s', cap))\n",
    "\n",
    "        texts = ct.loadAnns(ct.getAnnIds(imgIds=int(img_id)))\n",
    "        \n",
    "        #filtering\n",
    "        if 'size' in flags:\n",
    "            texts = exclude_small_text(texts, img_id , threshold=flags['size'])\n",
    "        if 'corner' in flags:\n",
    "            texts = exclude_corner_text(texts, img_id, threshold=flags['corner'])\n",
    "        \n",
    "        if len(texts) == 0:\n",
    "            continue\n",
    "\n",
    "        text_words = set()\n",
    "        coexist_count = 0\n",
    "        for text in texts:\n",
    "            if not 'utf8_string' in text:\n",
    "                continue\n",
    "            words = text['utf8_string'].upper().split(' ')\n",
    "            for word in words:\n",
    "                if word in text_words:\n",
    "                    continue\n",
    "                else:\n",
    "                    text_words.add(word)\n",
    "\n",
    "                if word in cap_words:\n",
    "                    coexist_count = coexist_count + 1      \n",
    "                    \n",
    "        if len(text_words) == 0:\n",
    "            continue\n",
    "\n",
    "        img_captions[img_id]['coexistence_data'] = {\n",
    "            'count'      : coexist_count,\n",
    "            'text_count' : len(text_words),\n",
    "            'rate'       : coexist_count/float(len(text_words))\n",
    "        }\n",
    "\n",
    "        coexists.append((coexist_count, len(text_words),coexist_count/float(len(text_words)), img_id))\n",
    "    return coexists\n",
    "\n",
    "coexists_large = calculate_population_coexist_stat({'size':0.05})\n",
    "coexists_center = calculate_population_coexist_stat({'corner':0.25})\n",
    "coexists_all = calculate_population_coexist_stat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1013\n"
     ]
    }
   ],
   "source": [
    "ids = [id for _, _, rate, id in coexists_all if rate >= 0.9]\n",
    "print len(ids)\n",
    "\n",
    "with open('../../input/high_coexist_img_ids.pkl', 'w+') as f:\n",
    "    pkl.dump(ids, f, protocol=pkl.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has size:10594\n",
      "Coexistence rate summary for images with larger texts.\n",
      "\n",
      "Total:\t10594;\t\tMean:\t\t0.135520;\tNonezero:\t2567\n",
      "Median:\t0.000000;\tMedian(H):\t0.000000;\tMedian(L):\t0.000000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.291835\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import statistics\n",
    "\n",
    "def get_stat(data):\n",
    "    if len(data)==0: return;\n",
    "    print \"\"\n",
    "    print \"Total:\\t%d;\\t\\tMean:\\t\\t%f;\\tNonezero:\\t%d\"%(len(data), statistics.mean(data), len(filter(lambda x:x!=0, data)))\n",
    "    print \"Median:\\t%f;\\tMedian(H):\\t%f;\\tMedian(L):\\t%f;\"%(statistics.median(data), statistics.median_high(data), statistics.median_low(data))\n",
    "    print \"Max:\\t%f;\\tMin:\\t\\t%f;\\tStd:\\t\\t%f\"%(max(data), min(data),statistics.stdev(data))\n",
    "    print \"\\n\"\n",
    "\n",
    "dataset = coexists_center\n",
    "print \"Dataset has size:%d\" % len(dataset)\n",
    "# for i in [0,1,2]:\n",
    "print \"Coexistence rate summary for images with larger texts.\"\n",
    "get_stat(map(lambda x:x[2], dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This cell calculates category-specific coexistence rate in a slightly different manner than above.\n",
    "Since we are focusing no a single annotation's attribute, we calculate coexistence rate for each annotation\n",
    "as (# of words in annotation that appears in caption)/(# of words in annotations, no duplicates).\n",
    "We calculate the mean for each category afterwords.\"\"\"\n",
    "\n",
    "def cal_ann_coexist_rate(ann):\n",
    "    if not \"utf8_string\"  in ann:\n",
    "        return None\n",
    "    caption = img_captions[str(ann['image_id'])]['captions']\n",
    "    text = ann['utf8_string']\n",
    "    count = 0 \n",
    "    seen = set()\n",
    "    for word in text:\n",
    "        if word in seen:\n",
    "            continue\n",
    "        if word in caption:\n",
    "            count+=1\n",
    "        seen.add(word)\n",
    "    return 1.0*count/len(seen)\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Calculate conditional coexistence mean for category.\n",
    "“class”                  :   str     # ‘machine printed’ or ‘handwritten’ or ‘others’\n",
    "“legibility”             :   str     # ‘legible’ or ‘illegible’\n",
    "“language”               :   str     # ‘english’ or ‘not english’ or ‘na’\n",
    "\"\"\"\n",
    "def calc_cond_coexist_mean():\n",
    "    class_score = {\"machine printed\":[], \"handwritten\":[], \"others\":[]}\n",
    "    legib_score = {\"legible\":[], \"illegible\":[]}\n",
    "    lang_score = {\"english\":[], \"not english\":[], \"na\":[]}\n",
    "    for img_id in img_captions.keys():\n",
    "        cap = img_captions[img_id]['captions'].upper()\n",
    "        cap_words = set(re.split('([,.])*\\s', cap))\n",
    "\n",
    "        anns = ct.loadAnns(ct.getAnnIds(imgIds=int(img_id)))\n",
    "        \n",
    "        #disregard any no-text images\n",
    "        if len(anns)==0:\n",
    "            continue\n",
    "            \n",
    "        #calculate coexistence rate for this image\n",
    "        for ann in anns:\n",
    "            rate = cal_ann_coexist_rate(ann)\n",
    "            #essentially disregard all illegible texts, which kinda betrays the point \n",
    "            if rate is None: \n",
    "                continue\n",
    "            class_score[ann['class']].append(rate)\n",
    "            legib_score[ann['legibility']].append(rate)\n",
    "            lang_score[ann['language']].append(rate)\n",
    "    return class_score, legib_score, lang_score\n",
    "\n",
    "#get statistics\n",
    "clas, legib, lang = calc_cond_coexist_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to pickle\n",
    "with open('../../stats/class_cond.pkl','wb') as f:\n",
    "    pkl.dump(clas, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(legib, f, protocol=pkl.HIGHEST_PROTOCOL)\n",
    "    pkl.dump(lang, f, protocol=pkl.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEACAYAAAB8nvebAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x113717dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(clas['machine printed'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditioned on [class]\n",
      "Machine printed:\n",
      "\n",
      "Total:\t94028;\t\tMean:\t\t0.542290;\tNonezero:\t66233\n",
      "Median:\t0.666667;\tMedian(H):\t0.666667;\tMedian(L):\t0.666667;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.433845\n",
      "\n",
      "\n",
      "Handwritten:\n",
      "\n",
      "Total:\t4829;\t\tMean:\t\t0.557745;\tNonezero:\t3593\n",
      "Median:\t0.714286;\tMedian(H):\t0.714286;\tMedian(L):\t0.714286;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.417883\n",
      "\n",
      "\n",
      "Others:\n",
      "\n",
      "Total:\t1990;\t\tMean:\t\t0.514228;\tNonezero:\t1303\n",
      "Median:\t0.500000;\tMedian(H):\t0.500000;\tMedian(L):\t0.500000;\n",
      "Max:\t1.000000;\tMin:\t\t0.000000;\tStd:\t\t0.439774\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.figure.Figure at 0x1071bc110>,\n",
       " <matplotlib.figure.Figure at 0x10733edd0>,\n",
       " <matplotlib.figure.Figure at 0x107800910>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print statistics\n",
    "def print_cond_stat(flags='CLA'):\n",
    "    \"\"\"\n",
    "    'C' for printing class, 'L' for printing legibility, 'A' for printing language\n",
    "    \"\"\"\n",
    "    def _incr(l=[-1]): l[0]+=1; return l[0];\n",
    "    figs = []\n",
    "    if 'C' in flags:\n",
    "        print(\"Conditioned on [class]\")\n",
    "        print(\"Machine printed:\")\n",
    "        get_stat(clas[\"machine printed\"])\n",
    "        f = plt.figure(_incr())\n",
    "        plt.hist(clas[\"machine printed\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "        plt.title(\"machine printed\")\n",
    "        figs.append(f)\n",
    "        print(\"Handwritten:\")\n",
    "        get_stat(clas[\"handwritten\"])\n",
    "        f = plt.figure(_incr())\n",
    "        plt.hist(clas[\"handwritten\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "        plt.title(\"handwritten\")\n",
    "        figs.append(f)\n",
    "        print(\"Others:\")\n",
    "        get_stat(clas[\"others\"])\n",
    "        f = plt.figure(_incr())\n",
    "        plt.hist(clas[\"others\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "        plt.title(\"others\")\n",
    "        figs.append(f)\n",
    "    if 'L' in flags:\n",
    "        print(\"Conditioned on [legibility]\")\n",
    "        print(\"Legible:\")\n",
    "        get_stat(legib[\"legible\"])\n",
    "        f = plt.figure(_incr())\n",
    "        plt.hist(legib[\"legible\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "        plt.title(\"legible\")\n",
    "        figs.append(f)\n",
    "#         print(\"Illegible:\")\n",
    "#         get_stat(legib[\"illegible\"])\n",
    "#         plt.figure(_incr())\n",
    "#         plt.hist(legib[\"illegible\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "    if 'A' in flags:\n",
    "        print(\"Conditioned on [language]\")\n",
    "        print(\"English\")\n",
    "        get_stat(lang[\"english\"])\n",
    "        f = plt.figure(_incr())\n",
    "        plt.hist(lang[\"english\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "        plt.title(\"english\")\n",
    "        figs.append(f)\n",
    "#         print(\"Not english\")\n",
    "#         get_stat(lang[\"not english\"])\n",
    "#         plt.figure(_incr())\n",
    "#         plt.hist(lang[\"not english\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "#         plt.title(\"not english\")\n",
    "#         print(\"NA\")\n",
    "#         get_stat(lang[\"na\"])\n",
    "#         plt.figure(_incr())\n",
    "#         plt.hist(lang[\"na\"], 20, normed= 0,  facecolor='r', alpha=0.5)\n",
    "#         plt.title(\"na\")\n",
    "    return figs\n",
    "\n",
    "print_cond_stat('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has size 21536\n",
      "Dataset has size 925\n",
      "Dataset has size 10594\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Demo of the histogram (hist) function with a few features.\n",
    "\n",
    "In addition to the basic histogram, this demo shows a few optional features:\n",
    "\n",
    "    * Setting the number of data bins\n",
    "    * The ``normed`` flag, which normalizes bin heights so that the integral of\n",
    "      the histogram is 1. The resulting histogram is a probability density.\n",
    "    * Setting the face color of the bars\n",
    "    * Setting the opacity (alpha value).\n",
    "\n",
    "\"\"\"\n",
    "def count(data, num_bins):\n",
    "    out=[]\n",
    "    step =1./num_bins\n",
    "    total = float(len(data))\n",
    "    for i in range(num_bins):\n",
    "        if i==num_bins-1:\n",
    "            out.append(len(filter(lambda x: i*step<=x[2],data))/total)\n",
    "            break\n",
    "        out.append(len(filter(lambda x: i*step<=x[2]<(i+1)*step ,data))/total)\n",
    "    return out\n",
    "\n",
    "def plot(data,color, num_bins=20):\n",
    "    print \"Dataset has size %d\"%len(data)\n",
    "    # the histogram of the data\n",
    "#     n, bins, patches = plt.hist(map(lambda x:x[2], data), num_bins, normed= 1,  facecolor=color, alpha=0.5)\n",
    "    plt.plot(np.arange(0,1,1./num_bins),count(data, num_bins), color+'-', linewidth=2)\n",
    "    \n",
    "    # add a 'best fit' line\n",
    "    plt.xlabel('Coexistence Rate')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Coexistence Rate Distribution')\n",
    "\n",
    "    # Tweak spacing to prevent clipping of ylabel\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "\n",
    "plot(coexists_all, 'r')\n",
    "plot(coexists_large, 'g')\n",
    "plot(coexists_center, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below is the different normalized distribution of coexistence rate of all images with texts vs. images with large text (area threshol=5%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(map(lambda x:x[2], coexists_all), 20,normed= 0,  facecolor='green', alpha=0.5)\n",
    "plt.title('All images')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(map(lambda x:x[2], coexists_large), 20, normed= 0,  facecolor='green', alpha=0.5)\n",
    "plt.xlabel('Images with large text')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(map(lambda x:x[2], coexists_center), 20, normed= 0,  facecolor='green', alpha=0.5)\n",
    "plt.xlabel('Images with center text')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Filter out the max most bunch\n",
    "\"\"\"\n",
    "# len(img_captions)\n",
    "\n",
    "high_rates_images = [img_captions[k] for k in img_captions.keys() if ('coexistence_data' in img_captions[k] and img_captions[k]['coexistence_data']['rate'] > 0.9)]\n",
    "print len(high_rates_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1, 0.0, '376385')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{u'caption': u'A large crowd is watching a baseball game.',\n",
       "  u'id': 587066,\n",
       "  u'image_id': 376385},\n",
       " {u'caption': u'Home plate at a professional baseball game, as everyone gets ready.',\n",
       "  u'id': 588155,\n",
       "  u'image_id': 376385},\n",
       " {u'caption': u'A group of baseball players standing on top of a green field.',\n",
       "  u'id': 588377,\n",
       "  u'image_id': 376385},\n",
       " {u'caption': u'the ump calling a strike the catcher throwing the ball back to the pitcher and the batter has a strike',\n",
       "  u'id': 591974,\n",
       "  u'image_id': 376385},\n",
       " {u'caption': u'A baseball game in progress with the batter up to plate.',\n",
       "  u'id': 592115,\n",
       "  u'image_id': 376385}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print coexists_center[0]\n",
    "img_captions['376385']['annotation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
